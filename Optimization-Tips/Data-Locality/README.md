# ğŸ“Š Data Locality - Localidade de Dados

Este mÃ³dulo demonstra o impacto da localidade de cache no desempenho de programas em C.

## ğŸ“ DescriÃ§Ã£o

O programa compara duas formas de percorrer uma matriz 2D, mostrando como o acesso sequencial (cache-friendly) Ã© significativamente mais rÃ¡pido que o acesso nÃ£o-sequencial.

## ğŸ“ Estrutura

```
Data-Locality/
â””â”€â”€ main.c      # ComparaÃ§Ã£o de localidade
```

## ğŸ”§ Como Funciona

### Boa Localidade (Row-major order)

```c
// Percorre linha por linha - CACHE FRIENDLY
void good_locality(int **matrix, int *result, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            result[i] += matrix[i][j];  // Acesso sequencial
        }
    }
}
```

### MÃ¡ Localidade (Column-major order)

```c
// Percorre coluna por coluna - CACHE UNFRIENDLY
void bad_locality(int **matrix, int *result, int n) {
    for (int j = 0; j < n; j++) {
        for (int i = 0; i < n; i++) {
            result[i] += matrix[i][j];  // Pula na memÃ³ria
        }
    }
}
```

## ğŸš€ CompilaÃ§Ã£o e ExecuÃ§Ã£o

```bash
gcc -O0 -o locality main.c  # Sem otimizaÃ§Ã£o para ver diferenÃ§a
./locality
```

## ğŸ“¤ Resultado Esperado (Matriz 10000x10000)

```
Boa localidade: 0.45 segundos
MÃ¡ localidade:  2.80 segundos
DiferenÃ§a: ~6x mais lento!
```

## ğŸ’¡ Por que isso acontece?

### Layout da MemÃ³ria (Row-major em C)

```
Matriz 3x3 na memÃ³ria:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [0,0] [0,1] [0,2] [1,0] [1,1] [1,2] [2,0] [2,1] [2,2] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         EndereÃ§os crescentes â†’
```

### Cache Line

```
Uma cache line tÃ­pica: 64 bytes = 16 ints

Acesso sequencial: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (16 hits por miss)
Acesso por coluna: â–ˆ___â–ˆ___â–ˆ___â–ˆ___ (1 hit por miss)
```

## ğŸ“Š Hierarquia de MemÃ³ria

| NÃ­vel | Tamanho | LatÃªncia |
|-------|---------|----------|
| Registradores | ~1 KB | 0 ciclos |
| L1 Cache | 32-64 KB | 4 ciclos |
| L2 Cache | 256 KB | 10 ciclos |
| L3 Cache | 8-32 MB | 40 ciclos |
| RAM | 8-64 GB | 200 ciclos |
| SSD | 256 GB+ | 10,000+ ciclos |

## ğŸ’¡ Conceitos Demonstrados

| Conceito | DescriÃ§Ã£o |
|----------|-----------|
| Localidade Espacial | Dados prÃ³ximos acessados juntos |
| Localidade Temporal | Dados recentes reutilizados |
| Cache Miss | Dado nÃ£o encontrado no cache |
| Cache Line | Unidade mÃ­nima de transferÃªncia |

## ğŸ”„ Boas PrÃ¡ticas

### 1. Percorrer arrays na ordem correta
```c
// BOM (C usa row-major)
for (i = 0; i < N; i++)
    for (j = 0; j < M; j++)
        a[i][j] = ...
```

### 2. Usar Structure of Arrays (SoA)
```c
// Array of Structures (AoS) - pode ser ruim
struct Particle { float x, y, z, vx, vy, vz; };
struct Particle particles[N];

// Structure of Arrays (SoA) - melhor localidade
struct Particles {
    float x[N], y[N], z[N];
    float vx[N], vy[N], vz[N];
};
```

### 3. Blocking/Tiling
```c
// Processar em blocos que cabem no cache
for (ii = 0; ii < N; ii += BLOCK)
    for (jj = 0; jj < N; jj += BLOCK)
        for (i = ii; i < min(ii+BLOCK, N); i++)
            for (j = jj; j < min(jj+BLOCK, N); j++)
                // processar
```

## ğŸ“š ReferÃªncias

- [What Every Programmer Should Know About Memory](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)
- [Cache-Oblivious Algorithms](https://en.wikipedia.org/wiki/Cache-oblivious_algorithm)
- [Data-Oriented Design](https://www.dataorienteddesign.com/dodbook/)
